Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?

Регуляризация - метод борьбы с переобучением, с помощью добавления некоторого штрафа за сложность модели.

Алгоритмы регуляризации:
1. стрижка деревьев - при обучении игнорирует критерий ‘max_depth’, после обучения обрезает деревья в обратном порядке, тем самым добиваясь уменьшение переобучения;
2. learning rate - добавление весов на предсказание деревьев на каждом шаге обучения.


По какому принципу рассчитывается "важность признака (feature_importance)" в ансамблях деревьев?

Строится дерево вопросов на основе оценкок энтропии или критерия Джинни на данных признаков.
И те признаки, на основе, которых было построенно больше вопросов в дереве и будут более важны (feature_importance).
